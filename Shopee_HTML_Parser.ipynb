{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shopee HTML Parser",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikanx101/G-Colab/blob/main/Shopee_HTML_Parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efl5wx9ZDFUQ"
      },
      "source": [
        "# **Shopee HTML Parser v1.0**\n",
        "\n",
        "## _Explanation_\n",
        "\n",
        "Per bulan lalu, _Shopee_ mengubah __API__ yang mereka gunakan untuk menampilkan data di _product pages_ mereka. Akibatnya pembacaan data `.json` menggunakan _headless browser_ yang selama ini kita andalkan menjadi tidak berguna lagi.\n",
        "\n",
        "Oleh karena itu, perlu ada alternatif cara lain untuk bisa mengambil data tersebut.\n",
        "\n",
        "Salah satu caranya adalah dengan _parsing html_ menggunakan _saved pages_ dari Shopee.\n",
        "\n",
        "## _How it works_\n",
        "\n",
        "Jika kita menyimpan suatu _webpage_ ke dalam _single html file_, maka __semua informasi__ yang ada pada _page_ tersebut otomatis telah tersimpan __meskipun__ terdapat _dynamic contents_.\n",
        "\n",
        "Dari _saved html_ tersebut, kita akan gunakan algoritma _parsing html_ untuk mendapatkan data yang diinginkan.\n",
        "\n",
        "## _Differences from Previous Shopee Scraper_\n",
        "\n",
        "Apa perbedaan dengan `Shopee Scraper` yang ada sebelumnya?\n",
        "\n",
        "1. `Shopee Scraper` mengambil data secara _real time_ sedangkan `Shopee HTML Parser` mengambil data hasil _saved html_.\n",
        "1. Pembacaan `Shopee Scraper` menjadi tidak _reliable_ karena __API__ yang sering berubah. Sedangkan `Shopee HTML Parser` lebih stabil.\n",
        "1. `Shopee Scraper` hanya membutuhkan _list url_ alamat produk berbentuk _file_ `.txt`. Sedangkan `Shopee HTML Parser` membutuhkan satu atau beberapa _saved html pages_ yang di-_compress_ dalam satu _file_ `.zip`. \n",
        "1. `Shopee HTML Parser` akan menghasilkan satu _file_ hasil dalam format `.csv` berisi informasi produk saja.\n",
        "\n",
        "## _Steps_\n",
        "\n",
        "1. _Save_ semua halaman produk __Shopee__ yang hendak diambil datanya dalam format _single html file_.\n",
        "1. _Compress_ semua _saved html_ tersebut ke dalam satu file `.zip`.\n",
        "1. _Upload_ _file_ `.zip` tersebut ke Google Colab ini.\n",
        "1. Isi nama _file_ `.zip` pada kolom isian yang diberikan.\n",
        "1. Klik `Runtime` -> `Run All`.\n",
        "1. Hasil _parsing_ akan tersedia dalam format `.csv`.\n",
        "\n",
        "## _Notes_\n",
        "\n",
        "Dilarang mengubah algoritma yang ada. Silakan di-_clone_ ke _GDrive_ sendiri jika memang ingin memodifikasi algoritma ini.\n",
        "\n",
        "_Created by:_ [Ikang](https://ikanx101.com/)\n",
        "\n",
        "*Last Modif:* Senin, 15 Maret 2021 ~ 20.30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfbUH6plFVze",
        "cellView": "form"
      },
      "source": [
        "#@title Nama File `.zip`\n",
        "rm(list=ls())\n",
        "library(dplyr)\n",
        "library(rvest)\n",
        "\n",
        "nama_file <- \"Saved HTML.zip\" #@param {type:\"string\"}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "cellView": "form",
        "id": "-LUTWiNrEyRG",
        "outputId": "4ed163a8-1bfe-4a25-ba02-012e3c0d0434"
      },
      "source": [
        "#@title Preparation data\n",
        "\n",
        "# Function\n",
        "shopee_parser = function(url){\n",
        "  x = read_html(url)\n",
        "  # nama produk\n",
        "  nama_produk = x %>% html_nodes(\".attM6y span\") %>% html_text()\n",
        "  # merek\n",
        "  merek = x %>% html_nodes(\"._3Qy6bH\") %>% html_text()\n",
        "  # harga\n",
        "  harga = x %>% html_nodes(\"._3e_UQT\") %>% html_text()\n",
        "  harga = gsub(\"[A-z]|\\\\.\",\"\",harga)\n",
        "  harga = as.numeric(harga)\n",
        "  # rating\n",
        "  rating = x %>% html_nodes(\"._1mYa1t\") %>% html_text() %>% as.numeric()\n",
        "  # terjual\n",
        "  terjual = x %>% html_nodes(\".aca9MM\") %>% html_text()\n",
        "  # seller\n",
        "  seller = x %>% html_nodes(\"._3uf2ae\") %>% html_text()\n",
        "  # lokasi\n",
        "  lokasi = x %>% html_nodes(\".aPKXeO:nth-child(6) div\") %>% html_text()\n",
        "  # waktu parsing\n",
        "  waktu = Sys.time()\n",
        "  # final\n",
        "  data = tibble(nama_produk,merek,harga,rating,terjual,seller,lokasi,marketplace = \"Shopee\",waktu)\n",
        "  return(data)\n",
        "}\n",
        "\n",
        "# ambil saved html\n",
        "saved_html = unzip(nama_file)\n",
        "cat(\"Keterangan:\")\n",
        "paste0(\"Ada \",length(saved_html),\" files html yang tersimpan dalam zip file tersebut\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keterangan:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"Ada 3 files html yang tersimpan dalam zip file tersebut\""
            ],
            "text/latex": "'Ada 3 files html yang tersimpan dalam zip file tersebut'",
            "text/markdown": "'Ada 3 files html yang tersimpan dalam zip file tersebut'",
            "text/html": [
              "'Ada 3 files html yang tersimpan dalam zip file tersebut'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "6tTdFQfPFtf6",
        "outputId": "7f0fcc23-9de1-488e-80dd-7c5b4dc7e25d"
      },
      "source": [
        "#@title Parsing HTML Files\n",
        "# inisiasi data awal\n",
        "raw_data = tibble()\n",
        "# proses looping parsing\n",
        "for(i in 1:length(saved_html)){\n",
        "  temp = shopee_parser(saved_html[i])\n",
        "  raw_data = rbind(temp,raw_data)\n",
        "}\n",
        "cat(\"Silakan download file csv\\n-- DONE --\")\n",
        "\n",
        "write.csv(raw_data,\"Data Hasil Parsing.csv\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Silakan download file csv\n",
            "-- DONE --"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}